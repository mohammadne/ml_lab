{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5j0UlUejsbo"
      },
      "source": [
        "**3.1. Accessing OpenAI LLMs via API in Python**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBeIeGuOjmCR"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlwIJ614j94_"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kB9IaBZkZrG"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtvl2O8Okdz-",
        "outputId": "797e476d-b700-4db2-eca1-f554a447d3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once upon a time, a gentle unicorn named Luna lived in a sparkling forest where moonbeams danced on her silver horn. One night, she followed a trail of glowing fireflies and discovered a hidden waterfall that sang the sweetest lullaby. With a happy sigh, Luna curled up by the water and dreamed of new adventures, knowing the magic of the woods would keep her safe until morning.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-2025-04-14\",\n",
        "    input=\"Tell me a three sentence bedtime story about a unicorn\"\n",
        ")\n",
        "\n",
        "print(response.output[0].content[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVj9nPUklOG8",
        "outputId": "771a1620-0f88-45ad-9ef0-c0ac927ba97b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Response(id='resp_68b3dcbea71c819790cb64cc80969f0304583d40a980a164', created_at=1756617918.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68b3dcbf8f088197afebd9a178602cee04583d40a980a164', content=[ResponseOutputText(annotations=[], text='Once upon a time, a gentle unicorn named Luna lived in a sparkling forest where moonbeams danced on her silver horn. One night, she followed a trail of glowing fireflies and discovered a hidden waterfall that sang the sweetest lullaby. With a happy sigh, Luna curled up by the water and dreamed of new adventures, knowing the magic of the woods would keep her safe until morning.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=79, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=96), user=None, store=True)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_-kZHWUl4PS"
      },
      "source": [
        "**Chat Completion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YfA5RDHmp5M",
        "outputId": "9323e13e-0fd6-4c03-b44a-cc7f5278f2a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Some examples of machine learning applications include self-driving cars, recommendation systems (like those used by Netflix or Amazon), fraud detection in banking, facial recognition technology, and medical diagnosis systems.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# maintain chat history in a list\n",
        "chat_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful chat assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is Machine Learning?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Machine Learning is a field of AI where systems learn patterns from data and improve without explicit programming.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you give me some examples?\"}\n",
        "]\n",
        "\n",
        "# send the full history to the API\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=chat_history\n",
        ")\n",
        "\n",
        "response = completion.choices[0].message.content\n",
        "print(response)\n",
        "\n",
        "# add the assistant's reply back into history for next round\n",
        "chat_history.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l318-hpAnPpb",
        "outputId": "e135b07e-e0ca-4d2b-e72c-406a93a2ebe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'You are a helpful chat assistant.'},\n",
              " {'role': 'user', 'content': 'What is Machine Learning?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Machine Learning is a field of AI where systems learn patterns from data and improve without explicit programming.'},\n",
              " {'role': 'user', 'content': 'Can you give me some examples?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Sure! Some examples of machine learning applications include self-driving cars, recommendation systems (like those used by Netflix or Amazon), fraud detection in banking, facial recognition technology, and medical diagnosis systems.'}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_history"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
